{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\my\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Loading the libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import xgboost as xgb\n",
    "#from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ignore this\n",
    "#reading the file containing the review with the ratings\n",
    "list_of_review = []\n",
    "with open('amazon_cells_labelled.txt','r',encoding = 'utf-8') as file:\n",
    "            mylist = [line.rstrip('\\n') for line in file]\n",
    "for each in mylist:\n",
    "    list_of_review.append(each.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Review sentiment\n",
      "0    So there is no way for me to plug it in here i...         0\n",
      "1                          Good case, Excellent value.         1\n",
      "2                               Great for the jawbone.         1\n",
      "3    Tied to charger for conversations lasting more...         0\n",
      "4                                    The mic is great.         1\n",
      "5    I have to jiggle the plug to get it to line up...         0\n",
      "6    If you have several dozen or several hundred c...         0\n",
      "7          If you are Razr owner...you must have this!         1\n",
      "8                  Needless to say, I wasted my money.         0\n",
      "9                     What a waste of money and time!.         0\n",
      "10                     And the sound quality is great.         1\n",
      "11   He was very impressed when going from the orig...         1\n",
      "12   If the two were seperated by a mere 5+ ft I st...         0\n",
      "13                            Very good quality though         1\n",
      "14   The design is very odd, as the ear \"clip\" is n...         0\n",
      "15   Highly recommend for any one who has a blue to...         1\n",
      "16                 I advise EVERYONE DO NOT BE FOOLED!         0\n",
      "17                                    So Far So Good!.         1\n",
      "18                                       Works great!.         1\n",
      "19   It clicks into place in a way that makes you w...         0\n",
      "20   I went on Motorola's website and followed all ...         0\n",
      "21   I bought this to use with my Kindle Fire and a...         1\n",
      "22            The commercials are the most misleading.         0\n",
      "23   I have yet to run this new battery below two b...         1\n",
      "24   I bought it for my mother and she had a proble...         0\n",
      "25                Great Pocket PC / phone combination.         1\n",
      "26   I've owned this phone for 7 months now and can...         1\n",
      "27   I didn't think that the instructions provided ...         0\n",
      "28   People couldnt hear me talk and I had to pull ...         0\n",
      "29                                Doesn't hold charge.         0\n",
      "..                                                 ...       ...\n",
      "970  I plugged it in only to find out not a darn th...         0\n",
      "971                                 Excellent product.         1\n",
      "972                        Earbud piece breaks easily.         0\n",
      "973                                     Lousy product.         0\n",
      "974  This phone tries very hard to do everything bu...         0\n",
      "975  It is the best charger I have seen on the mark...         1\n",
      "976                                  SWEETEST PHONE!!!         1\n",
      "977             :-)Oh, the charger seems to work fine.         1\n",
      "978  It fits so securely that the ear hook does not...         1\n",
      "979                                 Not enough volume.         0\n",
      "980                Echo Problem....Very unsatisfactory         0\n",
      "981  you could only take 2 videos at a time and the...         0\n",
      "982                            don't waste your money.         0\n",
      "983  I am going to have to be the first to negative...         0\n",
      "984  Adapter does not provide enough charging current.         0\n",
      "985  There was so much hype over this phone that I ...         0\n",
      "986  You also cannot take pictures with it in the c...         0\n",
      "987                            Phone falls out easily.         0\n",
      "988  It didn't work, people can not hear me when I ...         0\n",
      "989  The text messaging feature is really tricky to...         0\n",
      "990  I'm really disappointed all I have now is a ch...         0\n",
      "991                                Painful on the ear.         0\n",
      "992                   Lasted one day and then blew up.         0\n",
      "993                                      disappointed.         0\n",
      "994                              Kind of flops around.         0\n",
      "995  The screen does get smudged easily because it ...         0\n",
      "996  What a piece of junk.. I lose more calls on th...         0\n",
      "997                       Item Does Not Match Picture.         0\n",
      "998  The only thing that disappoint me is the infra...         0\n",
      "999  You can not answer calls with the unit, never ...         0\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Ignore this too\n",
    "#converting it into a dataframe\n",
    "\n",
    "df = pd.DataFrame([i[0] for i in list_of_review], columns=['Review'])\n",
    "df['sentiment'] = [i[1] for i in list_of_review]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "\n",
    "df =  pd.read_csv('data_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  sentiment\n",
       "0  So there is no way for me to plug it in here i...        0.1\n",
       "1                        Good case, Excellent value.        1.3\n",
       "2                             Great for the jawbone.        1.2\n",
       "3  Tied to charger for conversations lasting more...        0.2\n",
       "4                                  The mic is great.        1.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for any empty rows\n",
    "df=df[~df['Review'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 4, 1, 4, 1, 1, 5, 2, 2, 4, 5, 0, 4, 1, 5, 2, 4, 4, 0, 0, 5,\n",
       "       0, 5, 1, 4, 5, 0, 1, 1, 1, 4, 1, 2, 5, 1, 3, 2, 4, 2, 4, 0, 4, 1,\n",
       "       5, 3, 2, 0, 3, 0, 0, 3, 3, 3, 5, 3, 1, 4, 4, 0, 1, 5, 5, 1, 0, 0,\n",
       "       1, 3, 4, 4, 0, 1, 4, 3, 3, 5, 2, 4, 5, 2, 4, 0, 5, 1, 1, 5, 4, 0,\n",
       "       5, 5, 1, 3, 4, 0, 1, 5, 2, 0, 5, 2, 3, 2, 3, 4, 1, 4, 1, 5, 1, 1,\n",
       "       5, 4, 3, 4, 5, 3, 2, 4, 5, 3, 4, 1, 4, 0, 3, 4, 1, 1, 4, 0, 3, 5,\n",
       "       4, 5, 1, 1, 4, 3, 0, 5, 1, 2, 1, 2, 1, 4, 2, 1, 1, 2, 0, 1, 4, 4,\n",
       "       1, 5, 3, 5, 5, 5, 0, 4, 0, 4, 1, 4, 1, 4, 0, 0, 5, 1, 0, 4, 4, 4,\n",
       "       3, 1, 0, 1, 0, 1, 5, 2, 1, 5, 0, 4, 0, 1, 1, 4, 3, 1, 0, 3, 5, 1,\n",
       "       0, 1, 4, 4, 1, 5, 0, 4, 3, 4, 4, 1, 0, 0, 4, 3, 3, 5, 5, 0, 2, 5,\n",
       "       1, 1, 4, 1, 1, 4, 3, 1, 1, 2, 1, 0, 1, 4, 3, 5, 5, 4, 4, 1, 0, 2,\n",
       "       2, 0, 1, 5, 4, 4, 0, 5, 5, 5, 4, 5, 1, 1, 0, 4, 5, 4, 4, 3, 3, 2,\n",
       "       0, 3, 1, 3, 1, 3, 1, 3, 2, 5, 1, 4, 1, 4, 5, 4, 4, 5, 0, 5, 3, 4,\n",
       "       1, 1, 0, 4, 4, 1, 5, 2, 5, 5, 4, 3, 2, 1, 0, 5, 3, 3, 3, 4, 4, 0,\n",
       "       1, 1, 4, 0, 3, 4, 1, 0, 5, 5, 0, 5, 3, 2, 0, 3, 0, 4, 0, 0, 1, 1,\n",
       "       4, 4, 5, 3, 5, 1, 0, 2, 1, 1, 5, 0, 2, 4, 2, 5, 0, 4, 3, 1, 1, 4,\n",
       "       4, 0, 0, 4, 0, 2, 1, 4, 4, 0, 4, 0, 3, 5, 1, 4, 5, 5, 0, 5, 4, 2,\n",
       "       1, 1, 3, 1, 5, 0, 4, 4, 0, 5, 3, 0, 1, 5, 5, 3, 5, 1, 4, 5, 5, 3,\n",
       "       0, 4, 4, 1, 2, 4, 5, 5, 2, 5, 0, 4, 5, 1, 0, 5, 5, 1, 1, 5, 5, 0,\n",
       "       0, 0, 4, 1, 0, 3, 0, 4, 5, 0, 3, 3, 5, 4, 1, 5, 4, 2, 1, 5, 1, 1,\n",
       "       0, 0, 0, 3, 5, 5, 0, 5, 5, 0, 4, 3, 4, 1, 1, 0, 4, 4, 5, 1, 1, 5,\n",
       "       0, 1, 2, 4, 0, 0, 1, 4, 4, 1, 0, 3, 3, 3, 0, 0, 4, 1, 4, 0, 4, 5,\n",
       "       5, 0, 0, 0, 2, 0, 5, 4, 5, 3, 1, 0, 3, 0, 0, 3, 5, 5, 1, 2, 3, 1,\n",
       "       1, 0, 4, 1, 3, 1, 3, 3, 4, 5, 4, 5, 3, 0, 0, 5, 3, 4, 4, 1, 2, 5,\n",
       "       0, 4, 5, 2, 0, 2, 4, 0, 4, 4, 3, 1, 3, 1, 2, 1, 1, 5, 2, 2, 0, 4,\n",
       "       5, 5, 5, 5, 0, 1, 4, 3, 5, 1, 0, 1, 3, 0, 0, 1, 1, 4, 4, 2, 2, 3,\n",
       "       2, 4, 3, 1, 1, 1, 3, 1, 4, 1, 0, 4, 4, 0, 3, 1, 0, 1, 1, 3, 3, 3,\n",
       "       3, 2, 1, 4, 4, 5, 3, 0, 3, 4, 1, 1, 5, 1, 0, 3, 0, 4, 4, 4, 1, 1,\n",
       "       0, 0, 0, 4, 0, 2, 4, 1, 4, 1, 2, 2, 0, 5, 2, 4, 5, 0, 5, 4, 5, 0,\n",
       "       5, 1, 1, 3, 2, 3, 1, 1, 3, 4, 0, 3, 1, 3, 0, 2, 1, 4, 1, 3, 1, 0,\n",
       "       0, 4, 5, 3, 3, 0, 3, 1, 3, 3, 2, 2, 1, 3, 0, 0, 1, 2, 3, 5, 0, 1,\n",
       "       1, 5, 0, 3, 0, 1, 2, 3, 1, 5, 3, 1, 2, 0, 3, 1, 3, 3, 0, 5, 5, 3,\n",
       "       1, 5, 0, 3, 1, 4, 2, 1, 1, 5, 0, 2, 5, 0, 4, 0, 4, 3, 5, 0, 5, 3,\n",
       "       3, 3, 5, 2, 4, 0, 5, 4, 0, 4, 4, 3, 5, 4, 5, 0, 0, 0, 2, 5, 2, 5,\n",
       "       0, 4, 4, 1, 3, 3, 2, 1, 3, 1, 5, 5, 1, 5, 5, 0, 0, 0, 1, 1, 4, 4,\n",
       "       2, 1, 1, 4, 5, 4, 5, 3, 4, 0, 1, 0, 1, 1, 0, 0, 2, 3, 4, 2, 1, 5,\n",
       "       4, 3, 0, 5, 5, 4, 2, 2, 3, 4, 4, 0, 5, 1, 0, 5, 5, 5, 1, 3, 3, 3,\n",
       "       1, 1, 3, 3, 0, 5, 5, 3, 5, 5, 1, 3, 0, 3, 0, 4, 1, 2, 2, 0, 0, 2,\n",
       "       2, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 1, 1, 2, 3, 5, 3, 0, 3, 1, 0, 3,\n",
       "       1, 1, 2, 2, 3, 4, 3, 5, 4, 4, 0, 4, 3, 3, 3, 5, 4, 2, 5, 5, 0, 3,\n",
       "       2, 0, 3, 2, 3, 0, 0, 5, 1, 5, 0, 4, 5, 0, 1, 4, 4, 1, 2, 3, 1, 1,\n",
       "       5, 5, 0, 0, 5, 1, 3, 3, 3, 5, 1, 0, 1, 1, 0, 3, 3, 1, 3, 0, 3, 3,\n",
       "       4, 3, 0, 5, 0, 2, 0, 1, 2, 0, 3, 0, 1, 3, 5, 3, 5, 3, 0, 2, 0, 3,\n",
       "       3, 3, 3, 0, 3, 1, 5, 1, 5, 0, 5, 5, 5, 0, 3, 5, 3, 4, 3, 1, 1, 3,\n",
       "       0, 0, 1, 5, 0, 0, 0, 5, 5, 3, 3, 0, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 2, 1, 0, 0, 2, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y is encoded on a scale of 0 to 5\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into train and test\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(df['Review'], y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the text into count vector matrix\n",
    "\n",
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "\n",
    "ctv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_ctv =  ctv.transform(xtrain) \n",
    "xvalid_ctv = ctv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53\n"
     ]
    }
   ],
   "source": [
    "#Implementing Logistic Regression with the count vector matrix\n",
    "\n",
    "clf = LogisticRegression(penalty='l2',C=1.0)\n",
    "clf.fit(xtrain_ctv, ytrain)\n",
    "y_pred = clf.predict(xvalid_ctv)\n",
    "print(\"Accuracy: {}\".format(clf.score(xvalid_ctv, yvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.385\n"
     ]
    }
   ],
   "source": [
    "#Fitting Naive bayes with count vector matrix\n",
    "\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(xtrain_ctv, ytrain)\n",
    "print(\"Accuracy: {}\".format(clf.score(xvalid_ctv, yvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the text into Tfidf Vector\n",
    "\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "tfv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53\n"
     ]
    }
   ],
   "source": [
    "#Fitting Logistic Regression with the Tfidfvector\n",
    "\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "print(\"Accuracy: {}\".format(clf.score(xvalid_tfv, yvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44\n"
     ]
    }
   ],
   "source": [
    "#Fitting Naive bayes with the Tfidfvector\n",
    "\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "print(\"Accuracy: {}\".format(clf.score(xvalid_tfv, yvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [03:07, 11712.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2195884 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# load the GloVe vectors in a dictionary:\n",
    "os.chdir(\"C:\\\\Users\\\\Desktop\")\n",
    "embeddings_index = {}\n",
    "failed_words= []\n",
    "f = open('glove.840B.300d.txt',encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    try:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    except:\n",
    "        values = line.split()\n",
    "        word = values[0]     \n",
    "        failed_words.append(word)\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function creates a normalized vector for the whole sentence\n",
    "def sent2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 800/800 [00:00<00:00, 1709.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 5391.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# create sentence vectors using the above function for training and validation set\n",
    "xtrain_glove = [sent2vec(x) for x in tqdm(xtrain)]\n",
    "xvalid_glove = [sent2vec(x) for x in tqdm(xvalid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 70\n",
    "\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "\n",
    "# zero pad the sequences\n",
    "\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'i': 2,\n",
       " 'and': 3,\n",
       " 'it': 4,\n",
       " 'is': 5,\n",
       " 'a': 6,\n",
       " 'this': 7,\n",
       " 'to': 8,\n",
       " 'phone': 9,\n",
       " 'my': 10,\n",
       " 'for': 11,\n",
       " 'of': 12,\n",
       " 'not': 13,\n",
       " 'with': 14,\n",
       " 'very': 15,\n",
       " 'great': 16,\n",
       " 'on': 17,\n",
       " 'was': 18,\n",
       " 'in': 19,\n",
       " 'that': 20,\n",
       " 'good': 21,\n",
       " 'have': 22,\n",
       " 'you': 23,\n",
       " 'product': 24,\n",
       " 'quality': 25,\n",
       " 'had': 26,\n",
       " 'works': 27,\n",
       " 'headset': 28,\n",
       " 'battery': 29,\n",
       " 'but': 30,\n",
       " 'as': 31,\n",
       " 'sound': 32,\n",
       " 'so': 33,\n",
       " 'are': 34,\n",
       " 'well': 35,\n",
       " 'use': 36,\n",
       " 'all': 37,\n",
       " 'one': 38,\n",
       " 'ear': 39,\n",
       " 'would': 40,\n",
       " 'has': 41,\n",
       " 'work': 42,\n",
       " 'from': 43,\n",
       " 'your': 44,\n",
       " 'like': 45,\n",
       " 'be': 46,\n",
       " 'case': 47,\n",
       " 'if': 48,\n",
       " 'me': 49,\n",
       " 'than': 50,\n",
       " \"i've\": 51,\n",
       " \"don't\": 52,\n",
       " 'excellent': 53,\n",
       " 'up': 54,\n",
       " 'after': 55,\n",
       " 'time': 56,\n",
       " 'price': 57,\n",
       " \"it's\": 58,\n",
       " 'no': 59,\n",
       " 'really': 60,\n",
       " 'recommend': 61,\n",
       " '2': 62,\n",
       " 'does': 63,\n",
       " 'at': 64,\n",
       " 'out': 65,\n",
       " 'service': 66,\n",
       " 'or': 67,\n",
       " 'only': 68,\n",
       " 'best': 69,\n",
       " 'get': 70,\n",
       " \"i'm\": 71,\n",
       " 'also': 72,\n",
       " 'when': 73,\n",
       " 'nice': 74,\n",
       " 'just': 75,\n",
       " 'too': 76,\n",
       " 'worked': 77,\n",
       " 'love': 78,\n",
       " 'am': 79,\n",
       " 'these': 80,\n",
       " 'any': 81,\n",
       " 'new': 82,\n",
       " 'better': 83,\n",
       " 'first': 84,\n",
       " 'money': 85,\n",
       " 'item': 86,\n",
       " 'buy': 87,\n",
       " 'do': 88,\n",
       " 'an': 89,\n",
       " 'can': 90,\n",
       " 'more': 91,\n",
       " 'ever': 92,\n",
       " 'charger': 93,\n",
       " 'about': 94,\n",
       " 'because': 95,\n",
       " 'easy': 96,\n",
       " 'bluetooth': 97,\n",
       " 'even': 98,\n",
       " 'car': 99,\n",
       " 'now': 100,\n",
       " 'bought': 101,\n",
       " 'then': 102,\n",
       " 'reception': 103,\n",
       " 'they': 104,\n",
       " 'what': 105,\n",
       " 'comfortable': 106,\n",
       " 'did': 107,\n",
       " 'used': 108,\n",
       " 'could': 109,\n",
       " \"doesn't\": 110,\n",
       " 'its': 111,\n",
       " 'will': 112,\n",
       " 'happy': 113,\n",
       " 'which': 114,\n",
       " 'been': 115,\n",
       " 'poor': 116,\n",
       " 'bad': 117,\n",
       " 'while': 118,\n",
       " 'there': 119,\n",
       " 'made': 120,\n",
       " 'purchase': 121,\n",
       " 'still': 122,\n",
       " 'waste': 123,\n",
       " 'few': 124,\n",
       " 'cell': 125,\n",
       " 'charge': 126,\n",
       " 'off': 127,\n",
       " 'worst': 128,\n",
       " 'two': 129,\n",
       " 'fine': 130,\n",
       " 'far': 131,\n",
       " 'problem': 132,\n",
       " 'long': 133,\n",
       " 'life': 134,\n",
       " 'got': 135,\n",
       " 'piece': 136,\n",
       " 'calls': 137,\n",
       " 'enough': 138,\n",
       " 'camera': 139,\n",
       " 'them': 140,\n",
       " 'device': 141,\n",
       " 'same': 142,\n",
       " 'thing': 143,\n",
       " 'motorola': 144,\n",
       " 'right': 145,\n",
       " 'volume': 146,\n",
       " 'again': 147,\n",
       " 'problems': 148,\n",
       " 'using': 149,\n",
       " 'much': 150,\n",
       " 'fit': 151,\n",
       " 'make': 152,\n",
       " 'clear': 153,\n",
       " 'hear': 154,\n",
       " 'plug': 155,\n",
       " 'fits': 156,\n",
       " 'makes': 157,\n",
       " 'design': 158,\n",
       " 'other': 159,\n",
       " 'working': 160,\n",
       " 'into': 161,\n",
       " 'phones': 162,\n",
       " 'pretty': 163,\n",
       " 'over': 164,\n",
       " 'screen': 165,\n",
       " 'people': 166,\n",
       " 'think': 167,\n",
       " \"couldn't\": 168,\n",
       " 'disappointed': 169,\n",
       " 'looks': 170,\n",
       " 'call': 171,\n",
       " 'terrible': 172,\n",
       " 'lot': 173,\n",
       " 'everything': 174,\n",
       " 'months': 175,\n",
       " 'low': 176,\n",
       " 'amazon': 177,\n",
       " '5': 178,\n",
       " 'cool': 179,\n",
       " 'however': 180,\n",
       " 'highly': 181,\n",
       " 'years': 182,\n",
       " '1': 183,\n",
       " 'days': 184,\n",
       " 'cheap': 185,\n",
       " 'impressed': 186,\n",
       " 'customer': 187,\n",
       " 'wear': 188,\n",
       " 'how': 189,\n",
       " '3': 190,\n",
       " 'back': 191,\n",
       " 'year': 192,\n",
       " 'unit': 193,\n",
       " 'small': 194,\n",
       " 'junk': 195,\n",
       " 'look': 196,\n",
       " 'broke': 197,\n",
       " 'by': 198,\n",
       " 'found': 199,\n",
       " 'being': 200,\n",
       " 'tried': 201,\n",
       " 'verizon': 202,\n",
       " 'light': 203,\n",
       " 'talk': 204,\n",
       " 'their': 205,\n",
       " 'little': 206,\n",
       " 'voice': 207,\n",
       " 'horrible': 208,\n",
       " 'last': 209,\n",
       " 'buttons': 210,\n",
       " 'jabra': 211,\n",
       " 'without': 212,\n",
       " 'never': 213,\n",
       " 'real': 214,\n",
       " 'software': 215,\n",
       " 'quite': 216,\n",
       " 'went': 217,\n",
       " 'completely': 218,\n",
       " 'nokia': 219,\n",
       " 'internet': 220,\n",
       " 'looking': 221,\n",
       " 'several': 222,\n",
       " 'way': 223,\n",
       " 'big': 224,\n",
       " 'we': 225,\n",
       " 'since': 226,\n",
       " 'some': 227,\n",
       " 'gets': 228,\n",
       " 'both': 229,\n",
       " 'down': 230,\n",
       " 'most': 231,\n",
       " 'take': 232,\n",
       " \"didn't\": 233,\n",
       " 'say': 234,\n",
       " 'dropped': 235,\n",
       " 'useless': 236,\n",
       " 'audio': 237,\n",
       " 'loud': 238,\n",
       " 'company': 239,\n",
       " 'headsets': 240,\n",
       " 'need': 241,\n",
       " 'difficult': 242,\n",
       " 'picture': 243,\n",
       " 'around': 244,\n",
       " 'end': 245,\n",
       " 'perfectly': 246,\n",
       " 'headphones': 247,\n",
       " 'signal': 248,\n",
       " 'received': 249,\n",
       " 'find': 250,\n",
       " 'cable': 251,\n",
       " 'want': 252,\n",
       " 'crap': 253,\n",
       " 'priced': 254,\n",
       " 'going': 255,\n",
       " 'black': 256,\n",
       " 'three': 257,\n",
       " 'stay': 258,\n",
       " 'ears': 259,\n",
       " 'within': 260,\n",
       " 'less': 261,\n",
       " 'anyone': 262,\n",
       " 'hands': 263,\n",
       " 'before': 264,\n",
       " 'put': 265,\n",
       " 'go': 266,\n",
       " 'simple': 267,\n",
       " 'samsung': 268,\n",
       " 'came': 269,\n",
       " 'every': 270,\n",
       " 'minutes': 271,\n",
       " 'pleased': 272,\n",
       " 'line': 273,\n",
       " 'week': 274,\n",
       " 'started': 275,\n",
       " 'having': 276,\n",
       " 'especially': 277,\n",
       " 'mobile': 278,\n",
       " 'expect': 279,\n",
       " 'turn': 280,\n",
       " 'sturdy': 281,\n",
       " 'hard': 282,\n",
       " 'plastic': 283,\n",
       " 'cases': 284,\n",
       " 'different': 285,\n",
       " 'disappointing': 286,\n",
       " 'sure': 287,\n",
       " 'part': 288,\n",
       " 'pictures': 289,\n",
       " 'overall': 290,\n",
       " 'range': 291,\n",
       " 'high': 292,\n",
       " 'quickly': 293,\n",
       " 'cannot': 294,\n",
       " \"i'd\": 295,\n",
       " 'old': 296,\n",
       " 'weeks': 297,\n",
       " 'clarity': 298,\n",
       " 'keep': 299,\n",
       " 'many': 300,\n",
       " 'shipping': 301,\n",
       " 'couple': 302,\n",
       " 'original': 303,\n",
       " 'where': 304,\n",
       " 'disappointment': 305,\n",
       " 'nothing': 306,\n",
       " 'job': 307,\n",
       " 'none': 308,\n",
       " 'connection': 309,\n",
       " 'feature': 310,\n",
       " 'color': 311,\n",
       " 'important': 312,\n",
       " 'replace': 313,\n",
       " 'awesome': 314,\n",
       " 'charm': 315,\n",
       " 'data': 316,\n",
       " 'arrived': 317,\n",
       " 'charging': 318,\n",
       " \"can't\": 319,\n",
       " 'anything': 320,\n",
       " 'hold': 321,\n",
       " 'always': 322,\n",
       " 'free': 323,\n",
       " 'return': 324,\n",
       " 'strong': 325,\n",
       " 'belt': 326,\n",
       " 'helpful': 327,\n",
       " 'hours': 328,\n",
       " 'definitely': 329,\n",
       " 'another': 330,\n",
       " 'value': 331,\n",
       " 'feels': 332,\n",
       " 'razr': 333,\n",
       " 'easily': 334,\n",
       " 'know': 335,\n",
       " 'kind': 336,\n",
       " 'keyboard': 337,\n",
       " 'actually': 338,\n",
       " 'decent': 339,\n",
       " 'later': 340,\n",
       " 'buying': 341,\n",
       " 'blue': 342,\n",
       " 'she': 343,\n",
       " 'player': 344,\n",
       " 'earpiece': 345,\n",
       " 'must': 346,\n",
       " 'mic': 347,\n",
       " 'glad': 348,\n",
       " 'awful': 349,\n",
       " 'day': 350,\n",
       " 'support': 351,\n",
       " 'bars': 352,\n",
       " 'sucks': 353,\n",
       " 'hate': 354,\n",
       " 'said': 355,\n",
       " 'obviously': 356,\n",
       " 'were': 357,\n",
       " 'kept': 358,\n",
       " 'instructions': 359,\n",
       " 'treo': 360,\n",
       " 'extra': 361,\n",
       " 'try': 362,\n",
       " 'worth': 363,\n",
       " 'able': 364,\n",
       " 'holds': 365,\n",
       " 'rather': 366,\n",
       " 'seems': 367,\n",
       " 'deal': 368,\n",
       " 'tool': 369,\n",
       " 'sending': 370,\n",
       " 'easier': 371,\n",
       " 'seller': 372,\n",
       " 'place': 373,\n",
       " 'unfortunately': 374,\n",
       " 'absolutely': 375,\n",
       " 'fast': 376,\n",
       " 'goes': 377,\n",
       " 'lasts': 378,\n",
       " 'expected': 379,\n",
       " 'face': 380,\n",
       " 'comes': 381,\n",
       " 'unreliable': 382,\n",
       " 'bargain': 383,\n",
       " 'cingular': 384,\n",
       " 'comfortably': 385,\n",
       " 'wanted': 386,\n",
       " 'those': 387,\n",
       " 'should': 388,\n",
       " 'set': 389,\n",
       " 'here': 390,\n",
       " 'store': 391,\n",
       " 'others': 392,\n",
       " 'ringtones': 393,\n",
       " 'either': 394,\n",
       " 'lightweight': 395,\n",
       " 'purchased': 396,\n",
       " 'left': 397,\n",
       " 'usb': 398,\n",
       " 'clip': 399,\n",
       " 'mistake': 400,\n",
       " 'family': 401,\n",
       " 'leather': 402,\n",
       " 'lg': 403,\n",
       " 'plantronics': 404,\n",
       " 'ago': 405,\n",
       " 'satisfied': 406,\n",
       " 'order': 407,\n",
       " 'performance': 408,\n",
       " 'own': 409,\n",
       " '10': 410,\n",
       " 'times': 411,\n",
       " 'side': 412,\n",
       " 't': 413,\n",
       " 'away': 414,\n",
       " 'weak': 415,\n",
       " 'choice': 416,\n",
       " 'instead': 417,\n",
       " 'almost': 418,\n",
       " 'such': 419,\n",
       " 'wrong': 420,\n",
       " 'might': 421,\n",
       " 'dead': 422,\n",
       " 'slow': 423,\n",
       " 'drops': 424,\n",
       " 'area': 425,\n",
       " 'drain': 426,\n",
       " 'may': 427,\n",
       " 'getting': 428,\n",
       " 'fantastic': 429,\n",
       " 'avoid': 430,\n",
       " 'description': 431,\n",
       " 'through': 432,\n",
       " 'pairing': 433,\n",
       " 'ordered': 434,\n",
       " 'size': 435,\n",
       " 'setup': 436,\n",
       " 'needed': 437,\n",
       " 'give': 438,\n",
       " 'despite': 439,\n",
       " 'contacts': 440,\n",
       " 'dont': 441,\n",
       " 'chargers': 442,\n",
       " 'protection': 443,\n",
       " 'reasonably': 444,\n",
       " 'under': 445,\n",
       " 'wearing': 446,\n",
       " 'handsfree': 447,\n",
       " 'fall': 448,\n",
       " 'below': 449,\n",
       " 'pocket': 450,\n",
       " 'pc': 451,\n",
       " 'ease': 452,\n",
       " 'sprint': 453,\n",
       " 'plan': 454,\n",
       " 'speaker': 455,\n",
       " 'lacking': 456,\n",
       " 'features': 457,\n",
       " 'form': 458,\n",
       " 'match': 459,\n",
       " 'between': 460,\n",
       " '510': 461,\n",
       " 'plugged': 462,\n",
       " \"phone's\": 463,\n",
       " \"wasn't\": 464,\n",
       " 'jawbone': 465,\n",
       " 'trying': 466,\n",
       " 'finally': 467,\n",
       " 'longer': 468,\n",
       " 'experience': 469,\n",
       " 'trouble': 470,\n",
       " 'home': 471,\n",
       " 'microphone': 472,\n",
       " 'uncomfortable': 473,\n",
       " 'drop': 474,\n",
       " 'pair': 475,\n",
       " 'happier': 476,\n",
       " 'turned': 477,\n",
       " 'above': 478,\n",
       " 'replacement': 479,\n",
       " 'flip': 480,\n",
       " 'thought': 481,\n",
       " 'sharp': 482,\n",
       " 'probably': 483,\n",
       " 'bt': 484,\n",
       " 'pay': 485,\n",
       " 'worthless': 486,\n",
       " 'market': 487,\n",
       " 'tinny': 488,\n",
       " 'super': 489,\n",
       " 'charged': 490,\n",
       " 'scratched': 491,\n",
       " 'forever': 492,\n",
       " 'expensive': 493,\n",
       " 'beautiful': 494,\n",
       " 'palm': 495,\n",
       " 'decision': 496,\n",
       " 'noise': 497,\n",
       " 'sony': 498,\n",
       " 'earpieces': 499,\n",
       " 'earbud': 500,\n",
       " 'simply': 501,\n",
       " 'extremely': 502,\n",
       " 'thats': 503,\n",
       " 'rocks': 504,\n",
       " 'front': 505,\n",
       " 'seconds': 506,\n",
       " 'though': 507,\n",
       " 'seriously': 508,\n",
       " 'beep': 509,\n",
       " 'failed': 510,\n",
       " 'lost': 511,\n",
       " 'once': 512,\n",
       " 'everyone': 513,\n",
       " 'oh': 514,\n",
       " 'results': 515,\n",
       " 'care': 516,\n",
       " 'display': 517,\n",
       " 'given': 518,\n",
       " 'star': 519,\n",
       " 'feel': 520,\n",
       " 'construction': 521,\n",
       " 'perhaps': 522,\n",
       " 'refund': 523,\n",
       " 'outlet': 524,\n",
       " \"there's\": 525,\n",
       " 'conversations': 526,\n",
       " 'break': 527,\n",
       " 'included': 528,\n",
       " 'iphone': 529,\n",
       " 'wireless': 530,\n",
       " 'poorly': 531,\n",
       " 'plus': 532,\n",
       " 'holster': 533,\n",
       " 'who': 534,\n",
       " 'q': 535,\n",
       " 'provided': 536,\n",
       " 'unless': 537,\n",
       " 'network': 538,\n",
       " 'wife': 539,\n",
       " 'comfort': 540,\n",
       " 'yet': 541,\n",
       " 'computer': 542,\n",
       " 'static': 543,\n",
       " 'packaged': 544,\n",
       " 'coverage': 545,\n",
       " 'cellphone': 546,\n",
       " 'turns': 547,\n",
       " 'pda': 548,\n",
       " 'thank': 549,\n",
       " 'died': 550,\n",
       " 'save': 551,\n",
       " 'gotten': 552,\n",
       " 'alone': 553,\n",
       " 'worthwhile': 554,\n",
       " 'auto': 555,\n",
       " 'large': 556,\n",
       " 'least': 557,\n",
       " 'book': 558,\n",
       " 'joke': 559,\n",
       " 'ended': 560,\n",
       " 'd807': 561,\n",
       " 'advertised': 562,\n",
       " 'bar': 563,\n",
       " 'essentially': 564,\n",
       " 'forget': 565,\n",
       " 'tech': 566,\n",
       " 'switch': 567,\n",
       " 'install': 568,\n",
       " 'lose': 569,\n",
       " 'nearly': 570,\n",
       " 'during': 571,\n",
       " 'experienced': 572,\n",
       " 'things': 573,\n",
       " '6': 574,\n",
       " 'cumbersome': 575,\n",
       " 'unhappy': 576,\n",
       " 'maintain': 577,\n",
       " 'dropping': 578,\n",
       " 'placed': 579,\n",
       " 'room': 580,\n",
       " 'sides': 581,\n",
       " 'download': 582,\n",
       " 'laptop': 583,\n",
       " 'send': 584,\n",
       " 'additional': 585,\n",
       " 'costs': 586,\n",
       " 'skype': 587,\n",
       " 'ring': 588,\n",
       " 'holding': 589,\n",
       " 'igo': 590,\n",
       " 'tips': 591,\n",
       " 'protector': 592,\n",
       " 'date': 593,\n",
       " 'tremendous': 594,\n",
       " 'inside': 595,\n",
       " 'tries': 596,\n",
       " 'although': 597,\n",
       " 'impressive': 598,\n",
       " 'resolution': 599,\n",
       " \"won't\": 600,\n",
       " 'exchanged': 601,\n",
       " 'flaw': 602,\n",
       " 'please': 603,\n",
       " 'wired': 604,\n",
       " 'sounded': 605,\n",
       " 'ok': 606,\n",
       " \"wife's\": 607,\n",
       " 'understand': 608,\n",
       " 'wind': 609,\n",
       " 'pull': 610,\n",
       " 'unusable': 611,\n",
       " 'regarding': 612,\n",
       " '50': 613,\n",
       " 'wow': 614,\n",
       " 'catching': 615,\n",
       " 'bit': 616,\n",
       " 'paired': 617,\n",
       " 'answer': 618,\n",
       " 'att': 619,\n",
       " 'sleek': 620,\n",
       " 'storage': 621,\n",
       " 'chinese': 622,\n",
       " 'white': 623,\n",
       " 'consumer': 624,\n",
       " 'series': 625,\n",
       " 'quiet': 626,\n",
       " 'person': 627,\n",
       " 'saying': 628,\n",
       " 'docking': 629,\n",
       " 'station': 630,\n",
       " 'third': 631,\n",
       " 'numerous': 632,\n",
       " 'brand': 633,\n",
       " 'bottom': 634,\n",
       " 'huge': 635,\n",
       " 'ringing': 636,\n",
       " 'wise': 637,\n",
       " 'returned': 638,\n",
       " 'hand': 639,\n",
       " 'basically': 640,\n",
       " 'warning': 641,\n",
       " 'complaint': 642,\n",
       " 'stuff': 643,\n",
       " 'sizes': 644,\n",
       " 'feet': 645,\n",
       " 'listening': 646,\n",
       " 'music': 647,\n",
       " 'reason': 648,\n",
       " 'lasting': 649,\n",
       " 'recharge': 650,\n",
       " 'graphics': 651,\n",
       " 'caused': 652,\n",
       " 'exactly': 653,\n",
       " 'review': 654,\n",
       " 'broken': 655,\n",
       " 'operate': 656,\n",
       " 'shipped': 657,\n",
       " 'purpose': 658,\n",
       " 'along': 659,\n",
       " 'sometimes': 660,\n",
       " 'timeframe': 661,\n",
       " 'push': 662,\n",
       " 'he': 663,\n",
       " 'games': 664,\n",
       " 'together': 665,\n",
       " 'purchasing': 666,\n",
       " 'breaking': 667,\n",
       " 'sunglasses': 668,\n",
       " 'party': 669,\n",
       " 'quick': 670,\n",
       " 'waiting': 671,\n",
       " 'something': 672,\n",
       " 'tell': 673,\n",
       " 'allows': 674,\n",
       " 'smell': 675,\n",
       " 'hoping': 676,\n",
       " 'echo': 677,\n",
       " 'wasted': 678,\n",
       " 'reading': 679,\n",
       " 'cant': 680,\n",
       " 'figure': 681,\n",
       " 'video': 682,\n",
       " 'driving': 683,\n",
       " 'usually': 684,\n",
       " 'website': 685,\n",
       " 'sex': 686,\n",
       " 'pros': 687,\n",
       " 'come': 688,\n",
       " 'mp3': 689,\n",
       " 'cover': 690,\n",
       " 'let': 691,\n",
       " 'lock': 692,\n",
       " 'stars': 693,\n",
       " '20': 694,\n",
       " 'takes': 695,\n",
       " 'literally': 696,\n",
       " 'flash': 697,\n",
       " 'says': 698,\n",
       " 'beware': 699,\n",
       " 'user': 700,\n",
       " 'friendly': 701,\n",
       " 'activate': 702,\n",
       " 'etc': 703,\n",
       " 'im': 704,\n",
       " 'warranty': 705,\n",
       " 'cut': 706,\n",
       " 'loves': 707,\n",
       " 'batteries': 708,\n",
       " '4': 709,\n",
       " 'gels': 710,\n",
       " 'barely': 711,\n",
       " 'defective': 712,\n",
       " 'play': 713,\n",
       " 'incredible': 714,\n",
       " 'flimsy': 715,\n",
       " 'whatsoever': 716,\n",
       " 'slim': 717,\n",
       " 'month': 718,\n",
       " 'flawlessly': 719,\n",
       " 'appears': 720,\n",
       " 'current': 721,\n",
       " 'described': 722,\n",
       " 'certainly': 723,\n",
       " 'neither': 724,\n",
       " 'amazed': 725,\n",
       " 'crisp': 726,\n",
       " 'owned': 727,\n",
       " 'glasses': 728,\n",
       " 'cheaper': 729,\n",
       " 'took': 730,\n",
       " 'excited': 731,\n",
       " 'background': 732,\n",
       " 'buzzing': 733,\n",
       " 'override': 734,\n",
       " 'bother': 735,\n",
       " 'fire': 736,\n",
       " 'buyer': 737,\n",
       " 'careful': 738,\n",
       " 'spring': 739,\n",
       " 'next': 740,\n",
       " 'mess': 741,\n",
       " 'ipod': 742,\n",
       " 'stupid': 743,\n",
       " \"i'll\": 744,\n",
       " 'starts': 745,\n",
       " 'done': 746,\n",
       " 'stated': 747,\n",
       " 'button': 748,\n",
       " 'fails': 749,\n",
       " 'ability': 750,\n",
       " 'effect': 751,\n",
       " 'receiving': 752,\n",
       " 'connected': 753,\n",
       " 'keypad': 754,\n",
       " 'blackberry': 755,\n",
       " 'returning': 756,\n",
       " 'whole': 757,\n",
       " 'dialing': 758,\n",
       " 'particular': 759,\n",
       " 'model': 760,\n",
       " 'clearly': 761,\n",
       " 'sounds': 762,\n",
       " 'technology': 763,\n",
       " \"wouldn't\": 764,\n",
       " 'functionality': 765,\n",
       " 'w810i': 766,\n",
       " 'recognition': 767,\n",
       " 'logitech': 768,\n",
       " 'us': 769,\n",
       " 'secure': 770,\n",
       " 'full': 771,\n",
       " 'number': 772,\n",
       " 'told': 773,\n",
       " 'conversation': 774,\n",
       " 'eargels': 775,\n",
       " 'ask': 776,\n",
       " 'thin': 777,\n",
       " 'coming': 778,\n",
       " 'run': 779,\n",
       " \"that's\": 780,\n",
       " 'tones': 781,\n",
       " 'extended': 782,\n",
       " 'moto': 783,\n",
       " 'dying': 784,\n",
       " 'accept': 785,\n",
       " 'advise': 786,\n",
       " 'superb': 787,\n",
       " 'tooth': 788,\n",
       " 'hour': 789,\n",
       " 'unacceptable': 790,\n",
       " 'reviews': 791,\n",
       " 'house': 792,\n",
       " 'issues': 793,\n",
       " 'normal': 794,\n",
       " 'forced': 795,\n",
       " 'power': 796,\n",
       " 'wall': 797,\n",
       " 'adorable': 798,\n",
       " 'felt': 799,\n",
       " 'seem': 800,\n",
       " 'previous': 801,\n",
       " '7': 802,\n",
       " 'handy': 803,\n",
       " 'access': 804,\n",
       " 'notice': 805,\n",
       " 'making': 806,\n",
       " 'embarrassing': 807,\n",
       " 'accidentally': 808,\n",
       " 'touch': 809,\n",
       " 'red': 810,\n",
       " 'noticed': 811,\n",
       " 'breaks': 812,\n",
       " '325': 813,\n",
       " 'worn': 814,\n",
       " 'usable': 815,\n",
       " 'world': 816,\n",
       " 'useful': 817,\n",
       " 'machine': 818,\n",
       " 'neat': 819,\n",
       " 'gadget': 820,\n",
       " 'accompanied': 821,\n",
       " 'brilliant': 822,\n",
       " 'wallet': 823,\n",
       " 'type': 824,\n",
       " 'jiggle': 825,\n",
       " 'activated': 826,\n",
       " 'suddenly': 827,\n",
       " '11': 828,\n",
       " 'defect': 829,\n",
       " 'risk': 830,\n",
       " 'built': 831,\n",
       " 'ant': 832,\n",
       " 'mother': 833,\n",
       " 'reverse': 834,\n",
       " 'tape': 835,\n",
       " 'heavy': 836,\n",
       " 'keeps': 837,\n",
       " 'falling': 838,\n",
       " 'tools': 839,\n",
       " \"you'd\": 840,\n",
       " 'mins': 841,\n",
       " 'short': 842,\n",
       " 'sliding': 843,\n",
       " 'edge': 844,\n",
       " 'pants': 845,\n",
       " 'pockets': 846,\n",
       " 'wrongly': 847,\n",
       " 'reccomendation': 848,\n",
       " 'relative': 849,\n",
       " 'iriver': 850,\n",
       " 'spinn': 851,\n",
       " 'truly': 852,\n",
       " 'lasted': 853,\n",
       " 'blew': 854,\n",
       " \"microsoft's\": 855,\n",
       " 'rocketed': 856,\n",
       " 'destination': 857,\n",
       " 'unknown': 858,\n",
       " 'excrutiatingly': 859,\n",
       " 'minute': 860,\n",
       " 'thanks': 861,\n",
       " 'potentially': 862,\n",
       " 'fry': 863,\n",
       " '350': 864,\n",
       " 'jabra350': 865,\n",
       " 'freezes': 866,\n",
       " 'frequently4': 867,\n",
       " 'buyit': 868,\n",
       " '680': 869,\n",
       " 'realize': 870,\n",
       " 'earbugs': 871,\n",
       " 'means': 872,\n",
       " 'monkeys': 873,\n",
       " \"shouldn't\": 874,\n",
       " 'share': 875,\n",
       " 'dna': 876,\n",
       " 'copy': 877,\n",
       " 'humans': 878,\n",
       " 'beats': 879,\n",
       " 'fingers': 880,\n",
       " 'jerks': 881,\n",
       " 'aggravating': 882,\n",
       " 'securely': 883,\n",
       " 'hook': 884,\n",
       " 'directed': 885,\n",
       " 'canal': 886,\n",
       " 'continue': 887,\n",
       " 'periodically': 888,\n",
       " 'somehow': 889,\n",
       " 'immediately': 890,\n",
       " 'key': 891,\n",
       " 'pad': 892,\n",
       " 'lit': 893,\n",
       " 'smoothly': 894,\n",
       " 'motorolas': 895,\n",
       " 'snug': 896,\n",
       " 'encourage': 897,\n",
       " 'ir': 898,\n",
       " 'flaws': 899,\n",
       " 'exceptional': 900,\n",
       " 'owning': 901,\n",
       " 'official': 902,\n",
       " 'oem': 903,\n",
       " 'psyched': 904,\n",
       " 'appointments': 905,\n",
       " 'tone': 906,\n",
       " 'carries': 907,\n",
       " 'highest': 908,\n",
       " 'anti': 909,\n",
       " 'glare': 910,\n",
       " 'bulky': 911,\n",
       " 'land': 912,\n",
       " 'conditions': 913,\n",
       " 'fact': 914,\n",
       " 'rests': 915,\n",
       " 'lightly': 916,\n",
       " 'against': 917,\n",
       " 'address': 918,\n",
       " 'reboots': 919,\n",
       " 'rate': 920,\n",
       " 'rated': 921,\n",
       " 'megapixels': 922,\n",
       " 'renders': 923,\n",
       " 'images': 924,\n",
       " 'expectations': 925,\n",
       " 'relatively': 926,\n",
       " 'razor': 927,\n",
       " 'v3i': 928,\n",
       " 'combination': 929,\n",
       " 'bluetooths': 930,\n",
       " 'listener': 931,\n",
       " 'runs': 932,\n",
       " 'charges': 933,\n",
       " 'plays': 934,\n",
       " 'louder': 935,\n",
       " 'factor': 936,\n",
       " 'normally': 937,\n",
       " 'apart': 938,\n",
       " 'haul': 939,\n",
       " 'lense': 940,\n",
       " 'covered': 941,\n",
       " 'dustpan': 942,\n",
       " 'indoors': 943,\n",
       " 'disposable': 944,\n",
       " 'transmission': 945,\n",
       " 'totally': 946,\n",
       " 'unintelligible': 947,\n",
       " 'word': 948,\n",
       " 'solid': 949,\n",
       " 'instruction': 950,\n",
       " 'manual': 951,\n",
       " 'resistant': 952,\n",
       " 'couldnt': 953,\n",
       " 'earphone': 954,\n",
       " 'joy': 955,\n",
       " 'dit': 956,\n",
       " '5320': 957,\n",
       " 'supposedly': 958,\n",
       " '375': 959,\n",
       " 'apparently': 960,\n",
       " 'moving': 961,\n",
       " 'freeway': 962,\n",
       " 'speed': 963,\n",
       " 'complaints': 964,\n",
       " 'counterfeit': 965,\n",
       " 'darn': 966,\n",
       " 'creaks': 967,\n",
       " 'wooden': 968,\n",
       " 'floor': 969,\n",
       " '13': 970,\n",
       " 'bucks': 971,\n",
       " '2005': 972,\n",
       " 's710a': 973,\n",
       " 'seat': 974,\n",
       " 'otherwise': 975,\n",
       " 'thumbs': 976,\n",
       " 'distorted': 977,\n",
       " 'yell': 978,\n",
       " 'practical': 979,\n",
       " 'ample': 980,\n",
       " 'gadgets': 981,\n",
       " 'colored': 982,\n",
       " 'hoursthe': 983,\n",
       " 'thereplacement': 984,\n",
       " 'bmw': 985,\n",
       " 'fairly': 986,\n",
       " 'hearing': 987,\n",
       " 'palms': 988,\n",
       " 'explain': 989,\n",
       " 'jack': 990,\n",
       " 'wit': 991,\n",
       " 'hit': 992,\n",
       " 'reaching': 993,\n",
       " 'row': 994,\n",
       " 'keys': 995,\n",
       " 'perfect': 996,\n",
       " 'ps3': 997,\n",
       " 'exercise': 998,\n",
       " 'frustration': 999,\n",
       " 'investment': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 1878/1878 [00:00<00:00, 208240.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# create an embedding matrix for the words we have in the dataset\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_glove = np.array(xtrain_glove)\n",
    "xvalid_glove = np.array(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale the data before any neural net:\n",
    "scl = preprocessing.StandardScaler()\n",
    "xtrain_glove_scl = scl.fit_transform(xtrain_glove)\n",
    "xvalid_glove_scl = scl.transform(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need to binarize the labels for the neural net\n",
    "ytrain_enc = np_utils.to_categorical(ytrain)\n",
    "yvalid_enc = np_utils.to_categorical(yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A simple LSTM with glove embeddings and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(300,dropout=0.1, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - ETA: 37s - loss: 0.7124 - acc: 0.46 - ETA: 19s - loss: 0.7249 - acc: 0.39 - ETA: 13s - loss: 0.7106 - acc: 0.42 - ETA: 9s - loss: 0.7117 - acc: 0.4297 - ETA: 7s - loss: 0.7172 - acc: 0.412 - ETA: 6s - loss: 0.7095 - acc: 0.437 - ETA: 5s - loss: 0.7047 - acc: 0.450 - ETA: 4s - loss: 0.7008 - acc: 0.476 - ETA: 4s - loss: 0.6968 - acc: 0.493 - ETA: 3s - loss: 0.6930 - acc: 0.506 - ETA: 3s - loss: 0.6894 - acc: 0.534 - ETA: 2s - loss: 0.6859 - acc: 0.552 - ETA: 2s - loss: 0.6834 - acc: 0.562 - ETA: 2s - loss: 0.6805 - acc: 0.564 - ETA: 2s - loss: 0.6779 - acc: 0.568 - ETA: 1s - loss: 0.6756 - acc: 0.570 - ETA: 1s - loss: 0.6739 - acc: 0.575 - ETA: 1s - loss: 0.6666 - acc: 0.588 - ETA: 1s - loss: 0.6593 - acc: 0.600 - ETA: 0s - loss: 0.6518 - acc: 0.612 - ETA: 0s - loss: 0.6464 - acc: 0.617 - ETA: 0s - loss: 0.6399 - acc: 0.626 - ETA: 0s - loss: 0.6363 - acc: 0.635 - ETA: 0s - loss: 0.6481 - acc: 0.639 - 5s 6ms/step - loss: 0.6636 - acc: 0.6388 - val_loss: 0.6518 - val_acc: 0.6750\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - ETA: 2s - loss: 0.6781 - acc: 0.718 - ETA: 2s - loss: 0.5908 - acc: 0.765 - ETA: 2s - loss: 0.5643 - acc: 0.760 - ETA: 2s - loss: 0.5430 - acc: 0.765 - ETA: 2s - loss: 0.5451 - acc: 0.781 - ETA: 2s - loss: 0.5904 - acc: 0.739 - ETA: 1s - loss: 0.6034 - acc: 0.723 - ETA: 1s - loss: 0.6087 - acc: 0.718 - ETA: 1s - loss: 0.5937 - acc: 0.732 - ETA: 1s - loss: 0.5896 - acc: 0.731 - ETA: 1s - loss: 0.5832 - acc: 0.735 - ETA: 1s - loss: 0.5772 - acc: 0.737 - ETA: 1s - loss: 0.5726 - acc: 0.745 - ETA: 1s - loss: 0.5664 - acc: 0.747 - ETA: 1s - loss: 0.5658 - acc: 0.745 - ETA: 0s - loss: 0.5636 - acc: 0.748 - ETA: 0s - loss: 0.5682 - acc: 0.748 - ETA: 0s - loss: 0.5660 - acc: 0.744 - ETA: 0s - loss: 0.5576 - acc: 0.753 - ETA: 0s - loss: 0.5537 - acc: 0.750 - ETA: 0s - loss: 0.5485 - acc: 0.753 - ETA: 0s - loss: 0.5448 - acc: 0.755 - ETA: 0s - loss: 0.5390 - acc: 0.759 - ETA: 0s - loss: 0.5321 - acc: 0.768 - 3s 4ms/step - loss: 0.5351 - acc: 0.7638 - val_loss: 0.4579 - val_acc: 0.7800\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - ETA: 2s - loss: 0.5341 - acc: 0.687 - ETA: 2s - loss: 0.4465 - acc: 0.765 - ETA: 2s - loss: 0.4282 - acc: 0.781 - ETA: 2s - loss: 0.4838 - acc: 0.781 - ETA: 2s - loss: 0.4338 - acc: 0.812 - ETA: 2s - loss: 0.4394 - acc: 0.817 - ETA: 2s - loss: 0.4359 - acc: 0.825 - ETA: 1s - loss: 0.4130 - acc: 0.835 - ETA: 1s - loss: 0.4227 - acc: 0.833 - ETA: 1s - loss: 0.4329 - acc: 0.825 - ETA: 1s - loss: 0.4411 - acc: 0.821 - ETA: 1s - loss: 0.4330 - acc: 0.828 - ETA: 1s - loss: 0.4257 - acc: 0.831 - ETA: 1s - loss: 0.4241 - acc: 0.830 - ETA: 1s - loss: 0.4320 - acc: 0.825 - ETA: 1s - loss: 0.4330 - acc: 0.820 - ETA: 0s - loss: 0.4331 - acc: 0.821 - ETA: 0s - loss: 0.4313 - acc: 0.824 - ETA: 0s - loss: 0.4327 - acc: 0.825 - ETA: 0s - loss: 0.4323 - acc: 0.825 - ETA: 0s - loss: 0.4295 - acc: 0.824 - ETA: 0s - loss: 0.4280 - acc: 0.822 - ETA: 0s - loss: 0.4287 - acc: 0.820 - ETA: 0s - loss: 0.4239 - acc: 0.822 - 3s 4ms/step - loss: 0.4213 - acc: 0.8225 - val_loss: 0.4256 - val_acc: 0.8050\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - ETA: 2s - loss: 0.2197 - acc: 0.937 - ETA: 2s - loss: 0.3817 - acc: 0.843 - ETA: 2s - loss: 0.3923 - acc: 0.822 - ETA: 2s - loss: 0.4325 - acc: 0.804 - ETA: 2s - loss: 0.3932 - acc: 0.831 - ETA: 2s - loss: 0.3790 - acc: 0.843 - ETA: 2s - loss: 0.3546 - acc: 0.861 - ETA: 1s - loss: 0.3384 - acc: 0.875 - ETA: 1s - loss: 0.3531 - acc: 0.875 - ETA: 1s - loss: 0.3593 - acc: 0.871 - ETA: 1s - loss: 0.3570 - acc: 0.869 - ETA: 1s - loss: 0.3629 - acc: 0.867 - ETA: 1s - loss: 0.3582 - acc: 0.865 - ETA: 1s - loss: 0.3433 - acc: 0.870 - ETA: 1s - loss: 0.3421 - acc: 0.872 - ETA: 1s - loss: 0.3364 - acc: 0.875 - ETA: 0s - loss: 0.3333 - acc: 0.875 - ETA: 0s - loss: 0.3304 - acc: 0.876 - ETA: 0s - loss: 0.3299 - acc: 0.875 - ETA: 0s - loss: 0.3337 - acc: 0.873 - ETA: 0s - loss: 0.3410 - acc: 0.870 - ETA: 0s - loss: 0.3395 - acc: 0.870 - ETA: 0s - loss: 0.3366 - acc: 0.870 - ETA: 0s - loss: 0.3354 - acc: 0.871 - 3s 4ms/step - loss: 0.3340 - acc: 0.8712 - val_loss: 0.5444 - val_acc: 0.8000\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - ETA: 2s - loss: 0.4624 - acc: 0.843 - ETA: 2s - loss: 0.3297 - acc: 0.890 - ETA: 2s - loss: 0.2898 - acc: 0.895 - ETA: 2s - loss: 0.2818 - acc: 0.890 - ETA: 2s - loss: 0.3224 - acc: 0.850 - ETA: 2s - loss: 0.3087 - acc: 0.859 - ETA: 2s - loss: 0.3198 - acc: 0.852 - ETA: 1s - loss: 0.3090 - acc: 0.863 - ETA: 1s - loss: 0.3098 - acc: 0.864 - ETA: 1s - loss: 0.2975 - acc: 0.875 - ETA: 1s - loss: 0.2941 - acc: 0.877 - ETA: 1s - loss: 0.2860 - acc: 0.882 - ETA: 1s - loss: 0.2843 - acc: 0.882 - ETA: 1s - loss: 0.2863 - acc: 0.879 - ETA: 1s - loss: 0.2856 - acc: 0.883 - ETA: 1s - loss: 0.2783 - acc: 0.886 - ETA: 0s - loss: 0.2753 - acc: 0.887 - ETA: 0s - loss: 0.2744 - acc: 0.888 - ETA: 0s - loss: 0.2694 - acc: 0.891 - ETA: 0s - loss: 0.2703 - acc: 0.890 - ETA: 0s - loss: 0.2781 - acc: 0.885 - ETA: 0s - loss: 0.2890 - acc: 0.879 - ETA: 0s - loss: 0.2923 - acc: 0.877 - ETA: 0s - loss: 0.2998 - acc: 0.873 - 3s 4ms/step - loss: 0.3153 - acc: 0.8675 - val_loss: 0.5221 - val_acc: 0.7750\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - ETA: 2s - loss: 0.3432 - acc: 0.875 - ETA: 2s - loss: 0.3687 - acc: 0.890 - ETA: 2s - loss: 0.3292 - acc: 0.895 - ETA: 2s - loss: 0.2998 - acc: 0.914 - ETA: 2s - loss: 0.2841 - acc: 0.918 - ETA: 2s - loss: 0.2918 - acc: 0.901 - ETA: 2s - loss: 0.2717 - acc: 0.910 - ETA: 1s - loss: 0.2754 - acc: 0.906 - ETA: 1s - loss: 0.2799 - acc: 0.902 - ETA: 1s - loss: 0.2806 - acc: 0.896 - ETA: 1s - loss: 0.2725 - acc: 0.900 - ETA: 1s - loss: 0.2688 - acc: 0.901 - ETA: 1s - loss: 0.2718 - acc: 0.896 - ETA: 1s - loss: 0.2660 - acc: 0.899 - ETA: 1s - loss: 0.2755 - acc: 0.895 - ETA: 1s - loss: 0.2839 - acc: 0.894 - ETA: 0s - loss: 0.2938 - acc: 0.889 - ETA: 0s - loss: 0.2932 - acc: 0.887 - ETA: 0s - loss: 0.2875 - acc: 0.886 - ETA: 0s - loss: 0.2873 - acc: 0.884 - ETA: 0s - loss: 0.2824 - acc: 0.885 - ETA: 0s - loss: 0.2803 - acc: 0.887 - ETA: 0s - loss: 0.2841 - acc: 0.883 - ETA: 0s - loss: 0.2922 - acc: 0.881 - 3s 4ms/step - loss: 0.2921 - acc: 0.8837 - val_loss: 0.4005 - val_acc: 0.8100\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - ETA: 2s - loss: 0.1762 - acc: 0.937 - ETA: 2s - loss: 0.1806 - acc: 0.921 - ETA: 2s - loss: 0.1993 - acc: 0.916 - ETA: 2s - loss: 0.2022 - acc: 0.929 - ETA: 2s - loss: 0.2198 - acc: 0.912 - ETA: 2s - loss: 0.2255 - acc: 0.916 - ETA: 1s - loss: 0.2166 - acc: 0.924 - ETA: 1s - loss: 0.2259 - acc: 0.914 - ETA: 1s - loss: 0.2548 - acc: 0.902 - ETA: 1s - loss: 0.2404 - acc: 0.909 - ETA: 1s - loss: 0.2389 - acc: 0.909 - ETA: 1s - loss: 0.2500 - acc: 0.901 - ETA: 1s - loss: 0.2515 - acc: 0.903 - ETA: 1s - loss: 0.2494 - acc: 0.904 - ETA: 1s - loss: 0.2535 - acc: 0.902 - ETA: 1s - loss: 0.2660 - acc: 0.896 - ETA: 0s - loss: 0.2681 - acc: 0.893 - ETA: 0s - loss: 0.2655 - acc: 0.895 - ETA: 0s - loss: 0.2624 - acc: 0.898 - ETA: 0s - loss: 0.2599 - acc: 0.898 - ETA: 0s - loss: 0.2534 - acc: 0.900 - ETA: 0s - loss: 0.2507 - acc: 0.900 - ETA: 0s - loss: 0.2517 - acc: 0.899 - ETA: 0s - loss: 0.2479 - acc: 0.901 - 3s 4ms/step - loss: 0.2439 - acc: 0.9025 - val_loss: 0.4627 - val_acc: 0.7600\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - ETA: 2s - loss: 0.2353 - acc: 0.906 - ETA: 2s - loss: 0.3272 - acc: 0.875 - ETA: 2s - loss: 0.2982 - acc: 0.885 - ETA: 2s - loss: 0.3069 - acc: 0.882 - ETA: 2s - loss: 0.3041 - acc: 0.881 - ETA: 2s - loss: 0.2900 - acc: 0.890 - ETA: 2s - loss: 0.2843 - acc: 0.892 - ETA: 1s - loss: 0.2747 - acc: 0.898 - ETA: 1s - loss: 0.2828 - acc: 0.892 - ETA: 1s - loss: 0.2993 - acc: 0.881 - ETA: 1s - loss: 0.2971 - acc: 0.880 - ETA: 1s - loss: 0.3034 - acc: 0.880 - ETA: 1s - loss: 0.2904 - acc: 0.889 - ETA: 1s - loss: 0.2806 - acc: 0.895 - ETA: 1s - loss: 0.2728 - acc: 0.897 - ETA: 1s - loss: 0.2745 - acc: 0.892 - ETA: 0s - loss: 0.2664 - acc: 0.895 - ETA: 0s - loss: 0.2609 - acc: 0.895 - ETA: 0s - loss: 0.2669 - acc: 0.893 - ETA: 0s - loss: 0.2617 - acc: 0.895 - ETA: 0s - loss: 0.2574 - acc: 0.895 - ETA: 0s - loss: 0.2524 - acc: 0.899 - ETA: 0s - loss: 0.2504 - acc: 0.900 - ETA: 0s - loss: 0.2442 - acc: 0.904 - 3s 4ms/step - loss: 0.2448 - acc: 0.9012 - val_loss: 0.4413 - val_acc: 0.8250\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - ETA: 2s - loss: 0.2488 - acc: 0.875 - ETA: 2s - loss: 0.1905 - acc: 0.921 - ETA: 2s - loss: 0.2079 - acc: 0.916 - ETA: 2s - loss: 0.2098 - acc: 0.921 - ETA: 2s - loss: 0.2136 - acc: 0.918 - ETA: 2s - loss: 0.2715 - acc: 0.901 - ETA: 1s - loss: 0.2655 - acc: 0.897 - ETA: 1s - loss: 0.2716 - acc: 0.894 - ETA: 1s - loss: 0.2576 - acc: 0.899 - ETA: 1s - loss: 0.2418 - acc: 0.906 - ETA: 1s - loss: 0.2289 - acc: 0.909 - ETA: 1s - loss: 0.2118 - acc: 0.916 - ETA: 1s - loss: 0.2103 - acc: 0.915 - ETA: 1s - loss: 0.2035 - acc: 0.921 - ETA: 1s - loss: 0.2149 - acc: 0.916 - ETA: 0s - loss: 0.2121 - acc: 0.918 - ETA: 0s - loss: 0.2198 - acc: 0.915 - ETA: 0s - loss: 0.2139 - acc: 0.918 - ETA: 0s - loss: 0.2068 - acc: 0.921 - ETA: 0s - loss: 0.2106 - acc: 0.921 - ETA: 0s - loss: 0.2039 - acc: 0.924 - ETA: 0s - loss: 0.2000 - acc: 0.924 - ETA: 0s - loss: 0.2056 - acc: 0.922 - ETA: 0s - loss: 0.2048 - acc: 0.923 - 3s 4ms/step - loss: 0.2098 - acc: 0.9213 - val_loss: 0.4831 - val_acc: 0.7950\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253d013ef28>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=3, mode='auto')\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=32, epochs=20, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 70, 300)           563700    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_13 (Spatia (None, 70, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 70, 32)            28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 35, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1120)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 250)               280250    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 873,284\n",
      "Trainable params: 309,584\n",
      "Non-trainable params: 563,700\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.7207 - acc: 0.5087 - val_loss: 0.6799 - val_acc: 0.6200\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6821 - acc: 0.5862 - val_loss: 0.6614 - val_acc: 0.6775\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.6373 - acc: 0.6687 - val_loss: 0.5922 - val_acc: 0.7675\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.5492 - acc: 0.7437 - val_loss: 0.4948 - val_acc: 0.7925\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.4548 - acc: 0.7944 - val_loss: 0.4630 - val_acc: 0.7925\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.3844 - acc: 0.8319 - val_loss: 0.4609 - val_acc: 0.7725\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.3289 - acc: 0.8719 - val_loss: 0.4647 - val_acc: 0.7625\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.2747 - acc: 0.8875 - val_loss: 0.4402 - val_acc: 0.7900\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.2326 - acc: 0.9106 - val_loss: 0.4544 - val_acc: 0.8075\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.2211 - acc: 0.9156 - val_loss: 0.4734 - val_acc: 0.7750\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.1739 - acc: 0.9369 - val_loss: 0.5041 - val_acc: 0.7825\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.1635 - acc: 0.9469 - val_loss: 0.5255 - val_acc: 0.7775\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.1448 - acc: 0.9469 - val_loss: 0.5249 - val_acc: 0.7775\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.1242 - acc: 0.9513 - val_loss: 0.5638 - val_acc: 0.7900\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.0945 - acc: 0.9700 - val_loss: 0.5733 - val_acc: 0.7750\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.1060 - acc: 0.9606 - val_loss: 0.5956 - val_acc: 0.7825\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.0924 - acc: 0.9719 - val_loss: 0.6102 - val_acc: 0.7750\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.0586 - acc: 0.9819 - val_loss: 0.6789 - val_acc: 0.7725\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.0621 - acc: 0.9812 - val_loss: 0.6532 - val_acc: 0.7950\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.0608 - acc: 0.9812 - val_loss: 0.6805 - val_acc: 0.7950\n",
      "Accuracy: 79.50%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(xtrain_pad, ytrain_enc, validation_data=(xvalid_pad, yvalid_enc), epochs=20, batch_size=32, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(xvalid_pad, yvalid_enc, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
